{
  "hash": "734d5db44bdc0b77e24316d8d0dfb4c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Webscraping Aliexpress with Rselenium\"\nauthor: \"Aurelien Callens\"\nlang: en\ndate: \"2020-11-18\"\nexecute:\n  eval: false\ncategories:\n  - R\n  - Web scraping\n---\n\n\n\n\n  \nToday, I am going to show you how to scrape product prices from Aliexpress website. \n\n## A few words on web scraping\n\nBefore diving into the subject, you should be aware that web scraping is not allowed on certain websites. To know if it is the case for the website you want to scrape, I invit you to check the *robots.txt* page which should be located at the root of the website address. For Aliexpress this page is located here : <a href=\"https://www.aliexpress.com/robots.txt\" target=\"_blank\">www.aliexpress.com/robots.txt .</a>\n\n\nThis page indicates that webscrapping and crawling are not allowed on several page categories such as `/bin/*`, `/search/*`, `/wholesale*` for example. Fortunately for us, the `/item/*` category, where the product pages are stored, can be scraped. \n\n## RSelenium \n\n### Installation for Ubuntu 18.04 LTS \n\nThe installation for RSelenium was not as easy as expected and I encountered two errors. \n\nThe first error I got after I installed the package and tried the function *Rsdriver* was : \n\n```\nError in curl::curl_fetch_disk(url, x$path, handle = handle) :\nUnrecognized content encoding type. libcurl understands deflate, gzip content encodings.\n```\nThanks to <a href=\"https://github.com/ropensci/RSelenium/issues/186\" target=\"_blank\">this post</a>, I installed the missing package : *stringi*.\n\nOnce this error was addressed, I had a different one : \n\n```\nError: Invalid or corrupt jarfile /home/aurelien/.local/share/binman_seleniumserver/generic/4.0.0-alpha-2/selenium-server-standalone-4.0.0-alpha-2.jar\n```\n\nThis time the problem came from a corrupted file. Thanks to <a href=\"https://stackoverflow.com/questions/20680229/invalid-or-corrupt-jarfile-usr-local-bin-selenium-server-standalone-2-38-0-jar\" target=\"_blank\">this post</a>, I knew that I just had to download this file *selenium-server-standalone-4.0.0-alpha-2.jar* from the official <a href=\"https://selenium-release.storage.googleapis.com/index.html?path=4.0/\" target=\"_blank\">selenium website</a> and replace the corrupted file with it. \n\nI hope this will help some of you to install RSelenium with Ubuntu 18.04 LTS !\n\n### Opening a web browser \n\nAfter addressing the errors above, I can now open a firefox browser : \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RSelenium)\n\n#Open a firefox driver\nrD <- rsDriver(browser = \"firefox\") \nremDr <- rD[[\"client\"]]\n```\n:::\n\n\n\n### Logging in Aliexpress\n\nThe first step to scrape product prices on Aliexpress is to log in into your account:  \n \n\n::: {.cell}\n\n```{.r .cell-code}\nlog_id <- \"Your_mail_adress\"\npassword <- \"Your_password\"\n\n# Navigate to aliexpress login page \nremDr$navigate(\"https://login.aliexpress.com/\")\n\n# Fill the form with mail address\nremDr$findElement(using = \"id\", \"fm-login-id\")$sendKeysToElement(list(log_id))\n\n# Fill the form with password\nremDr$findElement(using = 'id', \"fm-login-password\")$sendKeysToElement(list(password))\n\n#Submit the login form by clicking Submit button\nremDr$findElement(\"class\", \"fm-button\")$clickElement()\n```\n:::\n\n\n\n### Navigating through the URLs and scraping the prices\n\nNow we have to navigate through a vector containing the URL of the aliexpress products we are interested in. Then we extract the price of the product by using the xpath of the product price of the webpage. The xpath of the element you want to scrape can be found by using the developer tool of chrome or firefox ( [tutorial here !](https://www.scrapingbee.com/blog/practical-xpath-for-web-scraping/) ). Once the price is extracted we have to ensure this price is in numerical format by removing any special character (euro or dollar sign) and replace the comma by a point for the decimal separator. Here is the R code: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n  url_list <- list(\"https://fr.aliexpress.com/store/product/Maxcatch-6Pcs-lot-Craws-Soft-Fishing-Lures-110mm-11-5g-Artificial-Bait-Soft-Bait-Craws-Lures/406467_32419930548.html?spm=a2g0w.12010612.0.0.5deb64f7836LnZ\",\n            \"https://fr.aliexpress.com/store/product/Maxcatch-Fishing-Lure-5Pcs-Lot-155mm-7-4g-3-colors-Swimbait-Artificial-Lizard-Soft-Fishing-Lures/406467_32613648610.html?spm=a2g0w.12010612.0.0.5deb64f7836LnZ\",\n            \"https://fr.aliexpress.com/store/product/Maxcatch-6Pcs-lot-Soft-Fishing-Lures-Minnow-Biat-95mm-6g-Jerkbait-Soft-Bait/406467_32419066106.html?spm=a2g0w.12010612.0.0.25fe5872CBqy0m\") \n\n# Allocate a vector to store the price of the products \ncurrentp <- c()\nfor(i in 1:length(url_list)){\n  \n  # Navigate to link [i]\n  remDr$navigate(url_list[i])\n  \n  # Find the price with an xpath selector and findElement.  \n  # Sometimes products can be removed and this could throw an error this is why we are using 'try' to handle the potential errors\n  \n  current <- try(remDr$findElement(using = \"xpath\",'//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"product-price-value\", \" \" ))]'), silent = T)\n  \n  #If error : current price is NA \n  if(class(current) =='try-error'){\n    currentp[i] <- NA\n  }else{\n    # Get the price \n    text <- unlist(current$getElementText())\n    \n    #Remove euro sign\n    text <- gsub(\"[^A-Za-z0-9,;._-]\",\"\",text)\n    \n    #Case when there is a range of price instead of one price + replace comma by point\n    if(grepl(\"-\", text)) {  \n      pe <- sub(\"-.*\",\"\",text) %>% sub(\",\", \".\", ., fixed = TRUE)\n      currentp[i] <-  as.numeric(pe)\n    }else{\n      currentp[i] <- as.numeric(sub(\",\", \".\", text, fixed = TRUE))\n  }\n  }\n  \nSys.sleep(4)\n}\n```\n:::\n\n\nBetween each link it is advised to wait a few seconds with *Sys.sleep(4)* to avoid being black-listed by the website. \n\n### Phantomjs version \n\nIf you execute the code above, you should see a firefox browser open and navigate through the list you provided. In case you don't want an active window, you can replace  firefox by phantomjs browser which is a headless browser (without a window). \n\nI don't know why but using `rsDriver(browser = \"phantomjs\")` does not work for me. I found <a href=\"https://cbelanger.netlify.app/post/web-scraping-in-r-selenium-firefox-and-phantomjs/\" target=\"_blank\">this post</a> which propose to start the phantomjs browser with the wdman package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(wdman)\nlibrary(RSelenium)\n# start phantomjs instance\nrPJS <- wdman::phantomjs(port = 4680L)\n\n# is it alive?\nrPJS$process$is_alive()\n\n#connect selenium to it?\nremDr <-  RSelenium::remoteDriver(browserName=\"phantomjs\", port=4680L)\n\n# open a browser\nremDr$open()\n\nremDr$navigate(\"http://www.google.com/\")\n\n# Screenshot of the headless browser to check if everything is working\nremDr$screenshot(display = TRUE)\n\n# Don't forget to close the browser when you are finished ! \nremDr$close()\n```\n:::\n\n\n\n### Conclusion \n\nOnce you have understand the basics of RSelenium and how to select elements inside HTML pages, it is really easy to write a script to scrape data on the web. This post was a short example to scrape the product price on Aliexpress pages but the script can be extended to scrape more data on each page such as the name of the item, its rating etc... It is even possible to automate this script to run daily in order to see price changes over time. As you see possibilities are endless!\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}